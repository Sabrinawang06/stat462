---
indent: true
output: 
  pdf_document:
    includes:
      in_header: header2.tex
      highlight: pygments
      number_sections: true
---
\begin{titlepage}
   \begin{center}
       \vspace*{4cm}
        
      \Huge
       \textbf{STAT 462 Final Project}
       
      \LARGE
       \vspace{0.5cm} 
        Regression Analaysis for Wine Data
 
       \vspace{2.5cm}
       \LARGE
       \textbf{Samuel Fox, Jiaying Liang, Luxin Wang}
 
       \vfill
        \vspace{0.8cm}
 
       Statistics Department\\
       Penn State University\\
       December 8, 2018
 
   \end{center}
\end{titlepage}


##Abstract

##Introduction

##Exploratory Data Analysis
\indent The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. We obtained the dataset from: http://archive.ics.uci.edu/ml/datasets/Wine+Quality . The website also provided the following references.\newline
1. Paulo Cortez, University of Minho, Guimar?es, Portugal, http://www3.dsi.uminho.pt/pcortez \space
2. A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal,2009.
\indent We randomly select 1000 samples of the dataset. It contains the following variables (units are not given in the dataset description): 

+ fixed acidity (grams/liter)
* volatile acidity (grams/liter)
* citric acid (grams/liter)
* residual sugar (grams/liter)
* chlorides (grams/liter)
* free sulfur dioxide (milligrams/liter)
* total sulfur dioxide (milligrams/liter)
* density (grams/cubic centimeter)
* pH: acidity (below 7) or alkalinity (over 7)
* sulphates:potassium sulfate (grams/liter)
* alcohol:percentage alcohol (% volume)
* type: type of wine (red/white)
+ Output variable (based on sensory data): quality (score between 0 and 10) 

\indent In this report, we are interested in what impact the different qulity of red wine and white wine. We build two different models, treating quality as continuous variable and categorical variable regardingly. Here are some simple summary output of this dataset:

```{r, echo=FALSE}
wine<-read.csv("wine_sample.csv", header=T)
#summary(wine[,-1])
attach(wine)
```

Consider quality as a response, these is the distribution for quality.

```{r,echo=FALSE,fig.width=5, fig.height=3}
par(mfrow=c(1,1))
hist(wine$quality, main="Distribution for quality")
```

\indent After ploting boxplots for all continuous variables. Density is the only variable does not have outliers and roughly symmetric (due to the random sample; few outliers exist when considering the whole dataset). Extreme outliers can be notieced within the chlorides variables (plot shown below). Most variables are skewed to the right with with the outliers on the larger side.  

```{r,echo=FALSE,fig.width=8,fig.height=4}
boxplot(wine$chlorides)
```

\indent Since the dataset is really big, looking at the pairwise sacatterplots will be relatively hard to identify outliers, we calculate the leverage of the potential predictors. Still considering the quality as response, we calculate the leverange of the potential model.

```{r, echo=FALSE,fig.width=4,fig.height=3}
X = model.matrix(type~.-type, data=wine)
H = X%*%solve(t(X)%*%X)%*%t(X)
h = diag(H)
#h #leverages
# The two threshholds are 2*(p/n) and 3*(p/n)
thresh2=2*12/1000
thresh3=3*12/1000
#plot(h,xlab="Obs #", ylab="Leverage", main="Leverage",cex=0.4,cex.lab=0.8,cex.main=1)
#abline(h=thresh2,lty=2,col="red")
#abline(h=thresh3,lty=2,col="blue")
#wine$color="black"
#wine$color[h>=thresh2]="red"
```

\indent There are the points with leverage greater then the threshhold 3*p/n:
```{r, echo=FALSE}
which(h>thresh3)
```

##Method

####1. Check Collinearity and Re-Scaling X's
```{r echo=FALSE,results="asis",fig.height=4,fig.width=4,message=FALSE}
#density has -0.7 with alcohol
library(car)
library(xtable)
plot(density~alcohol)
vif1<-vif(lm(quality~.-X-quality, data=wine)) #remove density
vif1<-as.data.frame(vif1)
vif1<-xtable(vif1,auto=TRUE)
#print(vif1,type="latex",comment=FALSE)
```

\indent From the VIF table we can see density has VIF of 25.061323 which mean severe collinearity (the plot shows the linear relationship between density and alcoho). So we have to remove this predictor, and this is the new VIF result.

```{r echo=FALSE, message=FALSE}
library(xtable)
vif2<-vif(lm(quality~.-X-density-quality, data=wine))
vif2<-as.data.frame(vif2)
vif2<-xtable(vif2,auto=TRUE)
#print(vif2,type="latex",comment=FALSE)

scaled.wine = scale(wine[c("fixed.acidity","volatile.acidity","citric.acid","residual.sugar","chlorides","free.sulfur.dioxide","total.sulfur.dioxide","pH","sulphates","alcohol")])

print(xtable(vif1), file="ta.tex", floating=FALSE)
print(xtable(vif2), file="tb.tex", floating=FALSE)
```
\begin{table}[ht]
\centering
\subfloat[VIF Full Predictor]{\label{tab:tab1a}\scalebox{.9}{\input{./ta}}}\quad
\subfloat[VIF Remove Density]{\label{tab:tab1b}\scalebox{.9}{\input{./tb}}}
\caption{VIF table}
\label{tab:tab1}
\end{table}

Looking at the new VIF result, no predictor variabel has VIF largely greater than 4. Thus the collinearity problem is eliminated. We also look in to the scale of X's. Since the orginal full linear model shows there is about 100 times difference between two $\beta$, we decided to scale the X's using the method "scale". In the following analysis, all continuous predictors are scaled.

####2. Regression Model treating Quality as continuous Variable and Model Selection
\indent 2.1 Full model \newline
\indent First we create dummy variable foe type variable, for which type red is 1, and type white is 0. Then we build a full model using quality as response variable. Here shows the full model summary and diagnosit plot
```{r echo=FALSE,results='asis',message=FALSE}
#create dummy variable
dummy=vector("numeric",1000)
dummy[wine$type=='red']=1
dummy[wine$type=='white']=0
scaled.wine<-as.data.frame(scaled.wine)
linear_full <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$citric.acid+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
xtable(linear_full,type='asis')
par(mfrow=c(2,2))
plot(linear_full)
```
\indent The residuals vs fitted looks like this because quality is a cateforical variable with 6 levels. However, since it has so many level, we treat it as a continous variable. Hence, the residuals vs fitted plot breaks into 6 lines. Accorrding to the Q-Q plot, the residuals follows a normal distribution. According to the residuals vs leverage plot, there is no influential point because there is no leverage exceed 0.5. 

\indent 2.2 Select model

\indent Using backward selection 
```{r echo=FALSE, results='asis', message=FALSE}
linear_red1 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red1)
linear_red2 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red2)
linear_red3 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red3)
linear_red4 <- lm(wine$quality~ scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red4)
linear_red5 <- lm(wine$quality~ +scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
xtable(linear_red5,type='latex')
```
We end up with 6 predictors. The reduced model includes volatile.acidity, residual.sugar, chlorides, sulphates , alcohol and dummy variables. 

using $R^2_{adj}$ to select model:

```{r echo=FALSE, message=FALSE}
library(leaps)
subset1=regsubsets(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$citric.acid+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy,nbest = 1,method = 'exhaustive',data=wine,nvmax = 13)
sum_subset<-summary(subset1)
#sum_subset$which
p_full=12
p=2:p_full
RSS_p=sum_subset$rss
totalSS=sum((wine$quality-mean(wine$quality))^2)
par(mfrow=c(2,2))
n=nrow(wine)
R2_adj=1-(RSS_p/(n-p))/(totalSS/(n-1))
#R2_adj
plot(p,R2_adj,xlab="Number of betas",ylab="Adjusted R-squared")

sigma_hat_full=summary(linear_full)$sigma
C_p=RSS_p/(sigma_hat_full^2)+2*p-n
#C_p

plot(p,C_p,xlab="Number of betas",ylab="Mallow's Cp")
abline(0,1)
aic_p=n*log(RSS_p/n)+2*p
#aic_p
plot(p,aic_p,xlab="Number of betas",ylab="AIC")
bic_p=n*log(RSS_p/n)+p*log(n)
#bic_p

plot(p,bic_p,xlab="Number of betas",ylab="BIC")
```
Max adjusted $R^2$ with 8 predictors. The model include fixed.acidity, volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxide, sulphates, alcohol and dummy variables.

Using $C_p$: when p=7 , with 6 predictors. The model include volatile.acidity, residual.sugar, chlorides, sulphates, alcohol and dummy variables.

Using AIC: when p=8,with 7 predictors. The model includes volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxide, sulphates, alcohol and dummy variables.

Using BIC: when p= 5, 4 predictors. The model includes volatile.acidity, residual.sugar, sulphates, alcohol and dummy variables.

In conclusion, we should use the model with 6 predictors bacause it has relatively big $R^2_{adj}$, low $C_p$, low aic and low bic. The final models includes volatile.acidity, residual.sugar, chlorides, sulphates, alcohol and dummy variables.

```{r echo=FALSE, results='asis', message=FALSE}
linear_red<-lm(wine$quality~scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
xtable(linear_red, type='latex')
par(mfrow=c(2,2))
plot(linear_red)
```
According to the summary output, the final model is \
y = 5.750 -0.250$X_{volatile.acidity}$ + 0.097$X_{residual.sugar}$ -0.0598$X_{chlorides}$+ 0.139$X_{sulphates}$ + 0.383$X_{alcohol}$ + 0.216$d_{type}$\

However, $R^2$ for this model is 0.2608 which means this model only represent 26.08% of the quality response. Hence, we need to use other method to find a better model. 

####3. Logistic Model treating Quality as Categorical Variable and Model Selection
\indent 3.1 Prepare Response Variable for Logistic Regression \newline
\indent To successfully perform the logistic regression analysis, we divide the quality variable into two groups, quality 3-5 is marked as low quality, which is assigned as value 0; quality 6-8 is marked as high quality, which is assigned as value 1. Using the function glm with family parameter of binomial. We get a full model of logistic regression. 
```{r echo=FALSE, results='asis', message=FALSE}
#####Logistic model#####

#####Logistic model#####

#create dummy variable
dummy=vector("numeric",nrow(wine))
dummy[wine$type=='red']=1
dummy[wine$type=='white']=0

#summary(wine$quality)

# 3-5 are lower quality (0), 6-8 are upper quality (1)
quality_logi<-vector('numeric',1000)
quality_logi[wine$quality<=5]=0
quality_logi[wine$quality>5]=1

######using scaled x's

scaled.wine = scale(wine[c("fixed.acidity","volatile.acidity","citric.acid","residual.sugar","chlorides","free.sulfur.dioxide","total.sulfur.dioxide","pH","sulphates","alcohol")])
scaled.wine<-cbind(scaled.wine,dummy)
#summary(scaled.wine)

scaled_logistic=glm(quality_logi~scaled.wine,family=binomial(link="logit"))
xtable(scaled_logistic, type='latex')
```
\indent 3.2 Model Selection 
\indent Observing the full logsitc regression summary, there are some variable not significantly contribute to the model. Using the function bestglm from the package "bestglm", the best logistic model is selected according to AIC. Then a presudo $R^2$ is calculated using deviance and null deviance from the model summary. The result is 0.1948436. This is a relatively low $R^2$, regardless this is not a "true" $R^2$
```{r echo=FALSE, results='asis', message=FALSE}
##bestglm selection
library(bestglm)
Xy2<-as.data.frame(cbind(scaled.wine,quality_logi))
#bestglm(Xy2,IC="AIC",family=binomial(link="logit"))

scaled.wine<-as.data.frame(scaled.wine)
best_logistic<-glm(quality_logi~volatile.acidity+residual.sugar+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+sulphates+alcohol+type+dummy,data=scaled.wine,family=binomial(link="logit"))
xtable(best_logistic, type='latex')
#1-best_logistic$deviance/best_logistic$null.deviance # "R-squared"
```
####4. Ordinal Logistic Regression
\indent 4.1 Even though logistic regression explain the relationship between significant predictors and quality as two level categorical variable, it does not fully explain the true nature of quality as a 6 level categorical variable. Thus, an ordinal logistic regression model is build to fully take consideration of 6 levels of quality. \newline
\indent Using the function polr from package MASS, treating quality as an ordered factor (with ordered level: 3<4<5<6<7<8), the full ordinal logistic model is constructed. Later, the p-value for each individual t-test is performed. Using backward selection, only variable volatile.acidity, residual.sugar, sulphates, and alcohol are left at $\alpha$=0.05. The best model summary is shown below (a new page called "ordinal" is used, since the clm function has a better ouput than polr function):
```{r echo=FALSE, message=FALSE}
##Change qulity into ordered factor
quality_order<-as.ordered(quality)

#####Ordinal logsitic
require(foreign)
require(ggplot2)
require(MASS)
require(Hmisc)
require(reshape2)
require(ordinal)


scaled.wine<-as.matrix(scaled.wine)
ordinal_fit<-polr(quality_order~scaled.wine,Hess=TRUE)
#summary(ordinal_fit)


ctable <- coef(summary(ordinal_fit))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
ctable <- cbind(ctable, "p value" = p)
#ctable

scaled.wine<-as.data.frame(scaled.wine)
best_ordinal<-clm(quality_order~volatile.acidity+residual.sugar+sulphates+alcohol)
summary(best_ordinal)
```
\indent 4.2 ANOVA Analysis for Variable Type
\indent During the model selection for ordinal logsitic selection, the dummy variable type caught our attention. It is the last variable to be removed from the backward selection with p-value of 0.0579 which is slightly above 0.05. Will this categorical variable of wine type actually impact the wine quality. A seperated anova analysis is performed along with a histogram overlaying the distribution of quality for red wine and white wine. The NOVA table shows that the quality is significantly different from red wine and white wine. 

```{r echo=FALSE,out.width = "70%"}

##Anova for quality and type
library(ggplot2)

anova_analysis<-aov(quality~type)
summary(anova_analysis)
ggplot(wine, aes(x = quality, fill = type)) + 
  geom_histogram(col = "black", alpha = 0.5, 
                 position = "identity") +
  scale_fill_discrete(name = "Quality Distribution for Different Type", 
                      breaks=c("A","B"), 
                      labels = c("red","white")) # plot

```

####5. Check Potential Outlier
```{r eacho=FALSE, echo=FALSE}
residuals = linear_red$residuals
sigma_hat = summary(linear_red)$sigma
X = model.matrix(wine$quality~scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
H = X%*%solve(t(X)%*%X)%*%t(X)
h = diag(H)
#h #leverages
r = residuals/(sigma_hat*sqrt(1-h))

p=5
#sum(h)

# The two threshholds are 2*(p/n) and 3*(p/n)
thresh2=2*p/n
thresh3=3*p/n
par(mfrow=c(2,2))
plot(h,xlab="Obs #", ylab="Leverage", main="Leverage")
abline(h=thresh2,lty=2,col="red")
abline(h=thresh3,lty=2,col="blue")

wine$color="black"
wine$color[h>=thresh2]="red"

r = residuals/(sigma_hat*sqrt(1-h))
plot(r, xlab="Obs #", ylab="Standardized Residuals", main="Standardize Residuals", col=wine$color)

t = r*sqrt((n-p-1)/(n-p-r^2))
wine$color[t>1.7]="green"
plot(t,xlab='Observation #',ylab='Studentized residuals',main='Studentized residuals', col=wine$color)

cook=(1/p)*r^2*h/(1-h)
plot(cook,xlab='Observation #',ylab='Cook\'s distance',main='Cook\'s distance', col=wine$color)

#which(h>=thresh3)
```
\indent Accoding to these plot, there are a lot of observations that have very high leverage (red points in leverage plot are observations with leverage greater than threshold 2p/n) which is most likely due to the fact that a logistic model would better represent them

##Result

##Conclusion

##Team Member Contribution

##Reference
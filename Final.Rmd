---
indent: true
output: 
  pdf_document:
    includes:
      in_header: header2.tex
      highlight: pygments
      number_sections: true
---
\begin{titlepage}
   \begin{center}
       \vspace*{4cm}
        
      \Huge
       \textbf{STAT 462 Final Project}
       
      \LARGE
       \vspace{0.5cm} 
        Regression Analaysis for Wine Data
 
       \vspace{2.5cm}
       \LARGE
       \textbf{Samuel Fox, Jiaying Liang, Luxin Wang}
 
       \vfill
        \vspace{0.8cm}
 
       Statistics Department\\
       Penn State University\\
       December 8, 2018
 
   \end{center}
\end{titlepage}


##Abstract


<p>The goal of this research project was to develop the best model to predict the quality of wine. We gathered a large dataset of wine data and took 1000 samples. We first checked assumptions of the dataset to make sure what we had was usable and would result in a working model based off of strong data. After checking for outliers, we did not detect any outlier in the dataset. We deleted density as it is collinear according to VIF output. From there we developed three models. We used backward elimination, RSS, Mallow’s Cp, AIC and BIC methods to select models. For our final linear regression model and the final logistic model, we ended up with the similar predictors including volatile acidity, residual sugar, chlorides, free sulfur dioxide, sulphates, alcohol and type. The final ordinal regression model has 4 predictors including volatile acidity, residual sugar, sulphates and alcohol. In addition, we perform an ANOVA test Chi-square  test to test whether different types of wine have different quality. The result shows us red wine has significantly higher quality than white wine.</p>


##Introduction

  The dataset that we used for analysis contained 1000 data points of wine sample from a larger dataset gathered from UCI’s wine+quality dataset. The variables considered were: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, ph, sulphate, alcohol, and type with the predicted variable being quality. Questions we asked when considering this dataset included are there any issues such as collinearity or outliers, does the data need to be scaled, what would be the best type of model for this scenario, and which interactions between variables, if any, are important in predicting the wine’s quality.\newline
The research objective is to find out the relationship between wine quality and the wine chemical contents. We are interested in the wine quality because it can be used for marketing purposes as well as helping the wine producers to decide how to improve wine quality in the future by determining which aspects to focus on. 


##Exploratory Data Analysis


  The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. We obtained the dataset from: http://archive.ics.uci.edu/ml/datasets/Wine+Quality . The website also provided the following references.\newline
1. Paulo Cortez, University of Minho, Guimar?es, Portugal, http://www3.dsi.uminho.pt/pcortez \space
2. A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal,2009.
  We randomly select 1000 samples of the dataset. It contains the following variables (units are not given in the dataset description): 

+ fixed acidity (grams/liter)
* volatile acidity (grams/liter)
* citric acid (grams/liter)
* residual sugar (grams/liter)
* chlorides (grams/liter)
* free sulfur dioxide (milligrams/liter)
* total sulfur dioxide (milligrams/liter)
* density (grams/cubic centimeter)
* pH: acidity (below 7) or alkalinity (over 7)
* sulphates:potassium sulfate (grams/liter)
* alcohol:percentage alcohol (% volume)
* type: type of wine (red/white)
+ Output variable (based on sensory data): quality (score between 0 and 10) 

  In this report, we are interested in what impact the different qulity of red wine and white wine. We build two different models, treating quality as continuous variable and categorical variable regardingly. Here are some simple summary output of this dataset:

```{r, echo=FALSE}
wine<-read.csv("wine_sample.csv", header=T)
#summary(wine[,-1])
attach(wine)
```

Consider quality as a response, these is the distribution for quality.

```{r,echo=FALSE,fig.width=5, fig.height=3}
par(mfrow=c(1,1))
hist(wine$quality, main="Distribution for quality")
```

  After ploting boxplots for all continuous variables, density is the only variable that does not have outliers and is roughly symmetric (due to the random sample; few outliers exist when considering the whole dataset). Extreme outliers can be notieced within the chlorides variable (plot shown below). Most variables are skewed to the right with the outliers on the larger side.  

```{r,echo=FALSE,fig.width=8,fig.height=3,fig.align='center'}
boxplot(wine$chlorides, horizontal = TRUE)
```

  Since the dataset is really big, looking at the pairwise sacatterplots will be relatively hard to identify outliers, so we calculate the leverage of the potential predictors. Still considering the quality as response, we calculate the leverage of the potential model.

```{r, echo=FALSE,fig.width=4,fig.height=3}
X = model.matrix(type~.-type, data=wine)
H = X%*%solve(t(X)%*%X)%*%t(X)
h = diag(H)
#h #leverages
# The two threshholds are 2*(p/n) and 3*(p/n)
thresh2=2*12/1000
thresh3=3*12/1000
#plot(h,xlab="Obs #", ylab="Leverage", main="Leverage",cex=0.4,cex.lab=0.8,cex.main=1)
#abline(h=thresh2,lty=2,col="red")
#abline(h=thresh3,lty=2,col="blue")
#wine$color="black"
#wine$color[h>=thresh2]="red"
```

  These are the points with leverage greater than the threshhold 3*p/n; notice observation #745 is the one point with extreme hight chloride content:
```{r, echo=FALSE}
which(h>thresh3)
```

##Method

####1. Check Collinearity and Re-Scaling X's
```{r echo=FALSE,results="asis",fig.height=4,fig.width=4,message=FALSE}
#density has -0.7 with alcohol
library(car)
library(xtable)
#plot(density~alcohol)
vif1<-vif(lm(quality~.-X-quality, data=wine)) #remove density
vif1<-as.data.frame(vif1)
vif1<-xtable(vif1,auto=TRUE)
#print(vif1,type="latex",comment=FALSE)
```

  From the VIF table we can see density has VIF of 25.061323 which means severe collinearity. So we have to remove this predictor, and this is the new VIF result.

```{r echo=FALSE, message=FALSE}
library(xtable)
vif2<-vif(lm(quality~.-X-density-quality, data=wine))
vif2<-as.data.frame(vif2)
vif2<-xtable(vif2,auto=TRUE)
#print(vif2,type="latex",comment=FALSE)

scaled.wine = scale(wine[c("fixed.acidity","volatile.acidity","citric.acid","residual.sugar","chlorides","free.sulfur.dioxide","total.sulfur.dioxide","pH","sulphates","alcohol")])

print(xtable(vif1), file="ta.tex", floating=FALSE)
print(xtable(vif2), file="tb.tex", floating=FALSE)
```
\begin{table}[ht]
\centering
\subfloat[VIF Full Predictor]{\label{tab:tab1a}\scalebox{.9}{\input{./ta}}}\quad
\subfloat[VIF Remove Density]{\label{tab:tab1b}\scalebox{.9}{\input{./tb}}}
\caption{VIF table}
\label{tab:tab1}
\end{table}

Looking at the new VIF result, no predictor variable has VIF largely greater than 4. Thus the collinearity problem is eliminated. We also look into the scale of X's. Since the orginal full linear model shows there is about 100 times difference between two $\beta$, we decided to scale the X's using the method "scale". In the following analysis, all continuous predictors are scaled.

####2. Regression Model treating Quality as continuous Variable and Model Selection
#####  2.1 Full model 
  First we create dummy variable foe type variable, for which type red is 1, and type white is 0. Then we build a full model using quality as response variable. Here shows the full model summary and diagnosit plot
```{r echo=FALSE,results='asis',message=FALSE,comment=FALSE}
#create dummy variable
dummy=vector("numeric",1000)
dummy[wine$type=='red']=1
dummy[wine$type=='white']=0
scaled.wine<-as.data.frame(scaled.wine)
linear_full <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$citric.acid+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#print(xtable(linear_full),type='latex',comment=FALSE)
par(mfrow=c(2,2))
plot(linear_full)
```

  The residuals vs fitted looks like this because quality is a cateforical variable with 6 levels. However, since it has so many levels, we treat it as a continous variable. Hence, the residuals vs fitted plot breaks into 6 lines. According to the Q-Q plot, the residuals follow a normal distribution. According to the residuals vs leverage plot, there are no influential points because there is no Cook's distance exceeding 0.5. Independent assumption is also met according to residual vs. observation plot which is not shown above (further discussion of check influencial points is in the last section). 

#####2.2 Select model

  First, we use backward selection with $\alpha$=0.5
```{r echo=FALSE, results='asis', message=FALSE,comnent=FALSE}
linear_red1 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red1)
linear_red2 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red2)
linear_red3 <- lm(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red3)
linear_red4 <- lm(wine$quality~ scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
#summary(linear_red4)
linear_red5 <- lm(wine$quality~ +scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
print(xtable(linear_red5),type='latex',comment=FALSE)
```

\begin{table}[ht]
\centering
\caption{Backward Selected Linear Model}
\label{tab:tab2}
\end{table}

We end up with 6 predictors. The reduced model includes volatile.acidity, residual.sugar, chlorides, sulphates , alcohol and dummy variables. 

Then, we try to use $R^2_{adj}$ to select model:

```{r echo=FALSE, message=FALSE,comment=FALSE}
library(leaps)
subset1=regsubsets(wine$quality~ scaled.wine$fixed.acidity+scaled.wine$volatile.acidity+scaled.wine$citric.acid+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$total.sulfur.dioxide+scaled.wine$pH+scaled.wine$sulphates+scaled.wine$alcohol+dummy,nbest = 1,method = 'exhaustive',data=wine,nvmax = 13)
sum_subset<-summary(subset1)
#sum_subset$which
p_full=12
p=2:p_full
RSS_p=sum_subset$rss
totalSS=sum((wine$quality-mean(wine$quality))^2)
par(mfrow=c(2,2))
n=nrow(wine)
R2_adj=1-(RSS_p/(n-p))/(totalSS/(n-1))
#R2_adj
plot(p,R2_adj,xlab="Number of betas",ylab="Adjusted R-squared")

sigma_hat_full=summary(linear_full)$sigma
C_p=RSS_p/(sigma_hat_full^2)+2*p-n
#C_p

plot(p,C_p,xlab="Number of betas",ylab="Mallow's Cp")
abline(0,1)
aic_p=n*log(RSS_p/n)+2*p
#aic_p
plot(p,aic_p,xlab="Number of betas",ylab="AIC")
bic_p=n*log(RSS_p/n)+p*log(n)
#bic_p

plot(p,bic_p,xlab="Number of betas",ylab="BIC")
```

Max adjusted $R^2$ with 8 predictors. The model include fixed.acidity, volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxide, sulphates, alcohol and dummy variables.

Using $C_p$: when p=7 , with 6 predictors. The model include volatile.acidity, residual.sugar, chlorides, sulphates, alcohol and dummy variables.

Using AIC: when p=8,with 7 predictors. The model includes volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxide, sulphates, alcohol and dummy variables.

Using BIC: when p= 5, 4 predictors. The model includes volatile.acidity, residual.sugar, sulphates, alcohol and dummy variables.

In conclusion, we should use the model with 7 predictors bacause it has relatively big $R^2_{adj}$, low $C_p$, low aic and low bic. The final models includes volatile.acidity, residual.sugar, chlorides, free.sulfur.dioxides, sulphates, alcohol and dummy variables.

```{r echo=FALSE, results='asis', message=FALSE,comment=FALSE}
linear_red<-lm(wine$quality~scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
print(xtable(linear_red), type='latex',comment=FALSE)
```
\begin{table}[ht]
\centering
\caption{Final Reduced Linear Model}
\label{tab:tab3}
\end{table}

```{r echo=FALSE, results='asis', message=FALSE,comment=FALSE}


#par(mfrow=c(2,2))
#plot(linear_red)
```

According to the summary output, the final model is \
y = 5.741 -0.246$X_{volatile.acidity}$ + 0.087$X_{residual.sugar}$ -0.059$X_{chlorides}$ +0.047$X_{free.sulfur.dioxide}$ + 0.136$X_{sulphates}$ + 0.388$X_{alcohol}$ + 0.256$d_{type}$\

However, $R^2$ for this model is 0.2627 which means this model only represent 26.27% of the quality response. Hence, we need to use other method to find a better model.  

####3. Logistic Model treating Quality as Categorical Variable and Model Selection
#####3.1 Prepare Response Variable for Logistic Regression

  To successfully perform the logistic regression analysis, we divide the quality variable into two groups, quality 3-5 is marked as low quality, which is assigned as value 0; quality 6-8 is marked as high quality, which is assigned as value 1. Using the function glm with family parameter of binomial. We get a full model of logistic regression. 
```{r echo=FALSE, results='asis', message=FALSE,comment=FALSE}
#####Logistic model#####

#####Logistic model#####

#create dummy variable
dummy=vector("numeric",nrow(wine))
dummy[wine$type=='red']=1
dummy[wine$type=='white']=0

#summary(wine$quality)

# 3-5 are lower quality (0), 6-8 are upper quality (1)
quality_logi<-vector('numeric',1000)
quality_logi[wine$quality<=5]=0
quality_logi[wine$quality>5]=1

######using scaled x's

scaled.wine = scale(wine[c("fixed.acidity","volatile.acidity","citric.acid","residual.sugar","chlorides","free.sulfur.dioxide","total.sulfur.dioxide","pH","sulphates","alcohol")])
scaled.wine<-cbind(scaled.wine,dummy)
#summary(scaled.wine)

scaled_logistic=glm(quality_logi~scaled.wine,family=binomial(link="logit"))
#print(xtable(scaled_logistic), type='latex',comment=FALSE)
```

#####3.2 Model Selection 

  Observing the full logsitc regression summary, there are some variables that do not significantly contribute to the model. Using the function bestglm from the package "bestglm", the best logistic model is selected according to AIC. Then a presudo $R^2$ is calculated using deviance and null deviance from the model summary. The result is 0.1948436. This is a relatively low $R^2$, regardless this is not a "true" $R^2$\newline

```{r echo=FALSE, results='asis', message=FALSE,comment=FALSE}
##bestglm selection
library(bestglm)
Xy2<-as.data.frame(cbind(scaled.wine,quality_logi))
#bestglm(Xy2,IC="AIC",family=binomial(link="logit"))

scaled.wine<-as.data.frame(scaled.wine)
best_logistic<-glm(quality_logi~volatile.acidity+residual.sugar+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+sulphates+alcohol+type+dummy,data=scaled.wine,family=binomial(link="logit"))
print(xtable(best_logistic), type='latex',comment=FALSE)
#1-best_logistic$deviance/best_logistic$null.deviance # "R-squared"
```

\begin{table}[ht]
\centering
\caption{Best Logistic Model Output}
\label{tab:tab4}
\end{table}

However, this logistic regression ignores the fact that quality has 6 different levels. So a better model is needed to fully explain the different levels of quality

####4. Ordinal Logistic Regression

#####4.1 Build the Ordinal Logistic Regression Model

Even though logistic regression explains the relationship between significant predictors and quality as a two level categorical variable, it does not fully explain the true nature of quality as a 6 level categorical variable. Thus, an ordinal logistic regression model is built to fully take into consideration the 6 levels of quality. \newline

Using the function polr from package MASS, treating quality as an ordered factor (with ordered level: 3<4<5<6<7<8), the full ordinal logistic model is constructed. Later, the p-value for each individual t-test is performed. Using backward selection, only variable volatile.acidity, residual.sugar, sulphates, and alcohol are left at $\alpha$=0.05. The best model summary is shown below (a new page called "ordinal" is used, since the clm function has a better ouput than polr function) as well as the plot showing change in probability for each level according to the change in different predictors:
```{r echo=FALSE, message=FALSE,comment=FALSE}
##Change qulity into ordered factor
quality_order<-as.ordered(quality)

#####Ordinal logsitic
require(foreign)
require(ggplot2)
require(MASS)
require(reshape2)
require(ordinal)


scaled.wine<-as.matrix(scaled.wine)
ordinal_fit<-polr(quality_order~scaled.wine,Hess=TRUE)
#summary(ordinal_fit)


ctable <- coef(summary(ordinal_fit))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
ctable <- cbind(ctable, "p value" = p)
#ctable

scaled.wine<-as.data.frame(scaled.wine)
best_ordinal<-clm(quality_order~volatile.acidity+residual.sugar+sulphates+alcohol)
```

\setcounter{table}{4}
```{r echo=FALSE, comment=FALSE, results='asis',message=FALSE, fig.height=6,out.weight="120%"}
require(stargazer)
#stargazer(linear_red)
stargazer(best_ordinal,title="Ordinal Logistic Regression Output", header=FALSE,omit.stat="n",dep.var.caption=' ',dep.var.labels.include=FALSE)

par(mfrow=c(2,2),oma = c(2, 1, 1, 1))
alcohol1<-seq(5,20,0.5)
xbeta <- alcohol1*0.879
logistic_cdf <- function(x) {
  return( 1/(1+exp(-x) ) )
}
p1 <- logistic_cdf( 3.9381 - xbeta )
p2 <- logistic_cdf( 5.8492 - xbeta ) - logistic_cdf( 3.9381 - xbeta )
p3 <- logistic_cdf( 9.0082 - xbeta ) - logistic_cdf( 5.8492 - xbeta )
p4 <- logistic_cdf( 11.5812 - xbeta ) - logistic_cdf(  9.0082- xbeta )
p6 <- logistic_cdf( 13.7805 - xbeta ) - logistic_cdf( 11.5812 - xbeta )
p8 <- 1 - logistic_cdf( 13.7805 - xbeta )
plot(alcohol1,p1, type='l', ylab='Probability',xlab='Alcohol Content', ylim=c(0,1),main="Probability of Quality \nvs. Alcohol Content",cex=3,cex.main=0.9)
lines(alcohol1,  p2, col='red')
lines(alcohol1,  p3, col='blue')
lines(alcohol1,  p4, col='green')
lines(alcohol1,  p6, col='purple')
lines(alcohol1,  p8, col='brown')
abline(v=14.05, lty=2, col="black")
abline(v=8, lty=2, col="black")

##Acidity
acidity<-seq(0,2,0.1)
xbeta <- acidity*-0.5021
logistic_cdf <- function(x) {
  return( 1/(1+exp(-x) ) )
}
p1 <- logistic_cdf( -5.76754 - xbeta )
p2 <- logistic_cdf( -3.85637 - xbeta ) - logistic_cdf( -5.76754 - xbeta )
p3 <- logistic_cdf( -0.69738 - xbeta ) - logistic_cdf( -3.85637 - xbeta )
p4 <- logistic_cdf( 1.87562 - xbeta ) - logistic_cdf(  -0.69738- xbeta )
p6 <- logistic_cdf( 4.07495 - xbeta ) - logistic_cdf( 1.87562 - xbeta )
p8 <- 1 - logistic_cdf( 4.07495 - xbeta )
plot(acidity,p1, type='l', ylab='Probability',xlab='Volatile Acidity', ylim=c(0,0.9),main="Probability of Quality \nvs. Volatile Acidity",cex=3,cex.main=0.9)
lines(acidity,  p2, col='red')
lines(acidity,  p3, col='blue')
lines(acidity,  p4, col='green')
lines(acidity,  p6, col='purple')
lines(acidity,  p8, col='brown')
abline(v=0.1, lty=2, col="black")
abline(v=1.33, lty=2, col="black")

#Sugar
sugar<-seq(0,27,1)
xbeta <- sugar*0.2262
logistic_cdf <- function(x) {
  return( 1/(1+exp(-x) ) )
}
p1 <- logistic_cdf( -5.76754 - xbeta )
p2 <- logistic_cdf( -3.85637 - xbeta ) - logistic_cdf( -5.76754 - xbeta )
p3 <- logistic_cdf( -0.69738 - xbeta ) - logistic_cdf( -3.85637 - xbeta )
p4 <- logistic_cdf( 1.87562 - xbeta ) - logistic_cdf(  -0.69738- xbeta )
p6 <- logistic_cdf( 4.07495 - xbeta ) - logistic_cdf( 1.87562 - xbeta )
p8 <- 1 - logistic_cdf( 4.07495 - xbeta )
plot(sugar,p1, type='l', ylab='Probability',xlab='Residual Sugar', ylim=c(0,1),main="Probability of Quality \nvs. Residual Sugar Content",cex=3,cex.main=0.9)
lines(sugar,  p2, col='red')
lines(sugar,  p3, col='blue')
lines(sugar,  p4, col='green')
lines(sugar,  p6, col='purple')
lines(sugar,  p8, col='brown')
abline(v=0.7, lty=2, col="black")
abline(v=26, lty=2, col="black")

##Sulphate
sulphate1<-seq(0,1.6,0.05)
xbeta <- sulphate1*2.68418
logistic_cdf <- function(x) {
  return( 1/(1+exp(-x) ) )
}
p1 <- logistic_cdf( -5.76754 - xbeta )
p2 <- logistic_cdf( -3.85637 - xbeta ) - logistic_cdf( -5.76754 - xbeta )
p3 <- logistic_cdf( -0.69738 - xbeta ) - logistic_cdf( -3.85637 - xbeta )
p4 <- logistic_cdf( 1.87562 - xbeta ) - logistic_cdf(  -0.69738- xbeta )
p6 <- logistic_cdf( 4.07495 - xbeta ) - logistic_cdf( 1.87562 - xbeta )
p8 <- 1 - logistic_cdf( 4.07495 - xbeta )
plot(sulphate1,p1, type='l', ylab='Probability',xlab='Sulphates', ylim=c(0,1),main="Probability of Quality \nvs. Sulphates Content",cex=3,cex.main=0.9)
lines(sulphate1,  p2, col='red')
lines(sulphate1,  p3, col='blue')
lines(sulphate1,  p4, col='green')
lines(sulphate1,  p6, col='purple')
lines(sulphate1,  p8, col='brown')
abline(v=0.25, lty=2, col="black")
abline(v=1.36, lty=2, col="black")

par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("right", lty=1, col=c("black", "red", "blue", "green", "purple", "brown"), 
       legend=c("3", "4", "5", "6", "7", "8"),horiz = FALSE, inset = c(0, 0), title = 'Quality Level',cex=0.6)

```

The graphs above show the change in probability for each quality level according to change of each significant predictor. And the range between dashed lines are the range included by the sample, while range outside the dash lines are prediction. For example, according to the model, when the alcohol content rises up to 15%, the probability of that wine having the quality level of 8 is higher than any other quality. 

#####4.2 ANOVA Analysis and Chi-Square test for Variable Type

During the model selection for ordinal logsitic selection, the dummy variable type caught our attention. It is the last variable to be removed from the backward selection with p-value of 0.0579 which is slightly above 0.05. Will this categorical variable of wine type actually impact the wine quality? A seperate anova analysis is performed along with a histogram overlaying the distribution of quality for red wine and white wine. The ANOVA table shows that the mean quality is significantly different from red wine and white wine. 

```{r echo=FALSE,out.width = "70%",results='asis',comment=FALSE, message=FALSE}

##Anova for quality and type
anova_analysis<-aov(quality~type)
#print(xtable(anova_analysis),comment=FALSE)

```

\begin{table}[ht]
\centering
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\ 
  \hline
type & 1 & 7.10 & 7.10 & 9.58 & 0.0020 \\ 
  Residuals & 998 & 739.10 & 0.74 &  &  \\ 
   \hline
\end{tabular}
\caption{ANOVA table}
\label{tab:tab6}
\end{table}


 \newpage 
 Otherwise, if we treat quality as categorical variable, given the frequency table of different quality levels for red wine and white wine, then perform Chi-square test for homogenity, the p-value is 0.008298, which is smaller than 0.05. Thus we reject the $H_0$ and conclude that red wine and white wine have a different quality distribution.\newline

```{r echo=FALSE, out.width="70%", results='asis',comment=FALSE,message=FALSE}

#frequency table
frenquency<-table(type, quality)
print(xtable(frenquency),comment=FALSE)

```
\begin{table}[h!]
\centering
\caption{Frequncy Table}
\label{tab:tab7}
\end{table}


For the ggplot down below, the different distributions of quality between red wine and white wine is shown. White wine has a more left skewed trend, showing white wine has more samples in the higher quality range.\newline

```{r echo=FALSE,out.width = "90%",comment=FALSE, message=FALSE,fig.align='center'}

library(ggplot2)
ggplot(wine,aes(x=quality)) + 
  geom_histogram(data=subset(wine,type == 'red'),aes(fill=type), alpha = 0.5,binwidth = 1)+
  geom_histogram(data=subset(wine,type == 'white'),aes(fill=type), alpha = 0.2,binwidth = 1)+
  scale_fill_manual(name="type", values=c("red","blue"),labels=c("Red","White"))+
  ggtitle("Distribution of Quality Between Wine Type")

```

\newpage
####5. Check Potential Outlier
```{r eacho=FALSE, echo=FALSE}
residuals = linear_red$residuals
sigma_hat = summary(linear_red)$sigma
X = model.matrix(wine$quality~scaled.wine$volatile.acidity+scaled.wine$residual.sugar+scaled.wine$chlorides+scaled.wine$free.sulfur.dioxide+scaled.wine$sulphates+scaled.wine$alcohol+dummy)
H = X%*%solve(t(X)%*%X)%*%t(X)
h = diag(H)
#h #leverages
r = residuals/(sigma_hat*sqrt(1-h))

p=5
#sum(h)

# The two threshholds are 2*(p/n) and 3*(p/n)
thresh2=2*p/n
thresh3=3*p/n
par(mfrow=c(2,2))
plot(h,xlab="Obs #", ylab="Leverage", main="Leverage",cex=0.3)
abline(h=thresh2,lty=2,col="red")
abline(h=thresh3,lty=2,col="blue")

wine$color="black"
wine$color[h>=thresh2]="red"

r = residuals/(sigma_hat*sqrt(1-h))
plot(r, xlab="Obs #", ylab="Standardized Residuals", main="Standardize Residuals", col=wine$color,cex=0.3)

t = r*sqrt((n-p-1)/(n-p-r^2))
wine$color[t>1.7]="green"
plot(t,xlab='Observation #',ylab='Studentized residuals',main='Studentized residuals', col=wine$color,cex=0.3)

cook=(1/p)*r^2*h/(1-h)
plot(cook,xlab='Observation #',ylab='Cook\'s distance',main='Cook\'s distance', col=wine$color,cex=0.3)

#which(h>=thresh3)
```
  
Accoding to these plots, there are a lot of observations that have very high leverage (red points in leverage plot are observations with leverage greater than threshold 2p/n) which is most likely due to the fact that a logistic model would better represent them. But no points with Cook's distance greater than 0.5, so no influencial point is detected. 

##Result


We decided to use an ordinal regression model as our final model. The final fitted model includes volatile.acidity, residual.sugar, sulphates and alcohol.

From this model we can see that volatile.acidity has a negative relationship with quality, and residual.sugar, sulphates, and alcohol have a positive relationship when the other predictors are considered as 0.

Looking at the ANOVA test and Chi-square test, it is apparent that the quality between red and white wine differs significantly. 


##Conclusion


We decided to use this model because an ordinal regression model has its responses as different ranks which can better represent the quality since the quality contains different levels. The chemical contents that determine the quality of wine are volatile acidity, residual sugar, sulphates and alcohol. We also acknowledged that better quality wine always contains higher alcohol content. In addition, we found out from the ANOVA test that white wine has better quality than red wine does on average. 

In this analysis, we need further investment in producing a better linear regression model considering interaction between the predictors. Overall, we think we need more information of wine in order to determine its quality, such as the quality of grapes, the year of its production and the method of wine production, etc. 


##Team Member Contribution

Sam worked on checking for outliers, leverages, and influential points as well as scaling the data.

Jianying worked on the linear model and checking the linear model assumptions

Luxin worked on the logistic models and their assumptions as well as setting up the final report.

All members contributed to the presentations slides and the final report edits.


##Reference

A.I. McLeod and Changjiang Xu (2018). bestglm: Best Subset GLM and
  Regression Utilities. R package version 0.37.
  https://CRAN.R-project.org/package=bestglm 
  
Christensen, R. H. B. (2018). ordinal - Regression Models for Ordinal Data.
  R package version 2018.8-25.
  http://www.cran.r-project.org/package=ordinal/.
  
Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
 R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 
 
H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag
  New York, 2016.
  
John Fox and Sanford Weisberg (2011). An {R} Companion to Applied
  Regression, Second Edition. Thousand Oaks CA: Sage. URL:
  http://socserv.socsci.mcmaster.ca/jfox/Books/Companion
  
Malshe, Ashwin. “Ordinal Regression in R.” Step by Step Solutions: T-Tests: Paired/Dependent and Independent, 20 Oct. 2016,     
  rstudio-pubs-static.s3.amazonaws.com/220675_90da5cd7a01c4a57b9f22ff2b89bc915.html.
  
“R Help 15: Logistic, Poisson & Nonlinear Regression.” 1.5 - The Coefficient of   Determination, r-Squared | STAT 501, Penn State University , onlinecourses.science.psu.edu/stat501/node/433/.
  
Venables, W. N. & Ripley, B. D. (2002) Modern Applied Statistics with S.
  Fourth Edition. Springer, New York. ISBN 0-387-95457-0
